---
layout: single
title: "graph contrastive using schnet"
---

# Abstract
새로운 3D contrastive 방법으로 학습을 하니 supervised 보다 성능이 좋아졌다.
pretrain data도 자기꺼만 사용하니 많이 필요없고 모델도 무겁지 않다.

최근 molecule 분야에 self-supervised 방법이 널리 사용되고 있다. label이 없는 데이터를 활용하여 data 자체의 supervision을 통해 데이터의 representation을 학습하는 방법.

기존 방법의 문제점
1) SSL시 molecule의 구조를 변경함. 분자는 이미지와 달리 단순 변환이라도 완전히 다른 특성을 초래할 수 있음.
2) 매우 많은 pretrain 데이터 사용
3) 매우 많은 모델 파라미터 사용
4) 3D 구조를 반영하지 못함

novelty
1) molecule의 성질을 유지시키면서 contrastive learning 하는 새로운 방법 (conformer, rotation, noise)
2) pretrain data로 자신만 사용
3) 적은 파라미터 사용
4) 3D 구조 활용

result
supervised 보다 pretrain 했을 경우 성능이 뛰어남. 우리의 방법이 분자 표현을 학습하는데에 적합한 방법임.


# 1. Introduction

# 2. Related Work

Schnet: 

SimCLR:


GraphCL: 
- Augmentation: Node dropping, Edge perturbation, Attribute masking, Subgraph
- Pretrain data: 456K from ChEMBL
- 

3D informax:

GeomGCL: 

MolCLR: 

GROVER: Transformer, 2D, **a very large number of parameters**

MoCL: 

MICRO-graph: 

MolCLE: 

ChemBERTa: 


# 3. Method

# 4. Experiments

# 5. Conclusion

# Reference
SimCLR


# 3줄 요약
1. **Schnet** 기반의 encoder
2. orthogonal function (**Gaussian function**)을 사용한 distance embedding
3. 3D GNN에 적합한 **contrastive learning** 방법 제시

<br />
molecule의 energy는 

![molecule_energy](..\images\2021-01-29-first\molecule_energy.png)
로 나타낼 수 있는데, $E_{bonds}$은 bond의 length에 따라 달라지고, $E_{angle}$은 bond들 간의 각도, $E_{torsion}$은 bond들의 회전, $E_{non-bonded}$은 bond를 형성하지 않는 atom들간의 상호작용을 나타낸다.